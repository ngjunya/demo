{
  "news":[{
    "id":"001",
       "title":"Smarter than GPT-4: Claude 3 AI catches researchers testing it",
  "date":"March 04, 2024",
  "author":"Loz Blain",
  "content":"Working on these next-gen intelligent AIs must be a freaky experience. As Anthropic announces the smartest model ever tested across a range of benchmarks, researchers recall a chilling moment when Claude 3 realized that it was being evaluated,Anthropic, you may recall, was founded in 2021 by a group of senior OpenAI team members, who broke away because they didn't agree with OpenAI's decision to work closely with Microsoft. The company's Claude and Claude 2 AIs have been competitive with GPT models, but neither Anthropic nor Claude have really broken through into public awareness.That could well change with Claude 3, since Anthropic now claims to have surpassed GPT-4 and Google's Gemini 1.0 model on a range of multimodal tests, setting new industry benchmarks across a wide range of cognitive tasks."
    },
    {
      "id":"002",
       "title":"Researchers tested leading AI models for copyright infringement using popular books, and GPT-4 performed worst",
  "date":"March 06, 2024",
  "author":"Hayden Field",
  "content":"The Perks of Being a Wallflower,” “The Fault in Our Stars,” “New Moon” — none are safe from copyright infringement by leading artificial intelligence models, according to research released Wednesday by Patronus AI. The company, founded by ex-Meta researchers, specializes in evaluation and testing for large language models — the technology behind generative AI products. Alongside the release of its new tool, CopyrightCatcher, Patronus AI released results of an adversarial test meant to showcase how often four leading AI models respond to user queries using copyrighted text.  The four models it tested were OpenAI’s GPT-4, Anthropic’s Claude 2, Meta’s Llama 2 and Mistral AI’s Mixtral. We pretty much found copyrighted content across the board, across all models that we evaluated, whether it’s open source or closed source,” Rebecca Qian, Patronus AI’s cofounder and CTO, who previously worked on responsible AI research at Meta, told CNBC in an interview. "
    },
     {
       "id":"003",
       "title":"Why Google’s AI tool was slammed for showing images of people of colour",
  "date":"March 09, 2024",
  "author":"Sarah Shamim",
  "content":"America’s founding fathers depicted as Black women and Ancient Greek warriors as Asian women and men – this was the world reimagined by Google’s generative AI tool, Gemini, in late February.The launch of the new image generation feature sent social media platforms into a flurry of intrigue and confusion. When users entered any prompts to create AI-generated images of people, Gemini was largely showing them results featuring people of colour – whether appropriate or not.X users shared laughs while repeatedly trying to generate images of white people on Gemini and failing to do so. While some instances were deemed humorous online, others, such as images of brown people wearing World War II Nazi uniforms with swastikas on them, prompted outrage, prompting Google to temporarily disable the tool. Here is more about Google Gemini and the recent controversy surrounding it. "
    }
  ]
}
